{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. setup dataset with train (seen 80%) and val (seen10%+unseen10%).\n",
    "2. train arcface with trainset.\n",
    "3. monitor roc with val."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "TRAIN = False\n",
    "load_epoch = 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import pandas as pd\n",
    "import albumentations as alb\n",
    "import os\n",
    "import matplotlib.pylab as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torchvision import transforms,models\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('./train_v2.csv')\n",
    "n_fold = 5\n",
    "for fold in range(n_fold):\n",
    "    train_idx = np.where((df_train['fold'] != fold) & (df_train['unseen'] == 0))[0]\n",
    "    valid_idx = np.where((df_train['fold'] == fold) | (df_train['unseen'] != 0))[0]\n",
    "    val_seen = np.where((df_train['fold'] == fold))[0]\n",
    "    val_unseen = np.where((df_train['unseen'] != 0))[0]\n",
    "\n",
    "df_train2 = df_train.loc[train_idx].reset_index(drop=True)\n",
    "df_dev = df_train.loc[val_seen].reset_index(drop=True)\n",
    "df_unseen = df_train.loc[val_unseen].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoaugument import ImageNetPolicy\n",
    "from PIL import Image\n",
    "\n",
    "RATIO = 1\n",
    "SIZE = 236\n",
    "SIZE2 = 128\n",
    "\n",
    "class GraphemeDataset(Dataset):\n",
    "    def __init__(self, label, data_aug=False, _type='train'):\n",
    "        self.label = label\n",
    "        self.data_aug_func = train_aug_trasforms = alb.Compose([\n",
    "                alb.RandomBrightnessContrast(0.05, 0.05, p=0.3),\n",
    "                alb.GaussNoise(var_limit=(10.0, 50.0), p=0.3),\n",
    "                alb.RandomSizedCrop(min_max_height=(int(70*RATIO), int(127*RATIO)), height=128, width=128, \n",
    "                                    w2h_ratio=1, interpolation=1, p=0.2),\n",
    "                alb.Rotate(limit=20, p=0.4),\n",
    "                alb.Cutout(num_holes=8, max_h_size=int(18*RATIO), max_w_size=int(18*RATIO), p=0.4),\n",
    "                \n",
    "                #alb.RandomResizedCrop(p=0.3),\n",
    "            ], p=1)\n",
    "        self.data_aug = data_aug\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.label)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        label1 = self.label.vowel_diacritic.values[idx]\n",
    "        label2 = self.label.grapheme_root.values[idx]\n",
    "        label3 = self.label.consonant_diacritic.values[idx]\n",
    "        image = cv2.imread(\"train{}/\".format(SIZE)+self.label.image_id.values[idx]+\".png\")\n",
    "        image = cv2.resize(image, (SIZE2,SIZE2))\n",
    "\n",
    "        imagetrans = self.data_aug_func(image=image)[\"image\"]\n",
    "        \n",
    "        # to torch formats\n",
    "        image = np.array(image)/255\n",
    "        image = np.transpose(image, (2,0,1))\n",
    "        imagetrans = np.array(imagetrans)/255\n",
    "        imagetrans = np.transpose(imagetrans, (2,0,1))\n",
    "        return image, imagetrans, label1,label2,label3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image = GraphemeDataset(df_train2, data_aug=True)\n",
    "train_loader = torch.utils.data.DataLoader(train_image,batch_size=batch_size,shuffle=True, num_workers=8)\n",
    "dev_image = GraphemeDataset(df_dev)\n",
    "dev_loader = torch.utils.data.DataLoader(dev_image,batch_size=batch_size,shuffle=True, num_workers=8)\n",
    "unseen_image = GraphemeDataset(df_unseen)\n",
    "unseen_loader = torch.utils.data.DataLoader(unseen_image, batch_size=batch_size,shuffle=True, num_workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pretrainedmodels\n",
    "model_name = \"resnet34\"\n",
    "basemodel = pretrainedmodels.__dict__[model_name](num_classes=1000, pretrained='imagenet')\n",
    "basemodel = nn.Sequential(*list(basemodel.children())[:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics import ArcMarginProduct\n",
    "class mymodel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(mymodel, self).__init__()\n",
    "        self.features = basemodel\n",
    "        #self.conv1 = nn.Conv2d(1, 64, kernel_size=3, padding=1, bias=False)\n",
    "        if model_name == \"resnet34\" or model_name == \"resnet18\":\n",
    "            num_ch = 512\n",
    "        else:\n",
    "            num_ch = 2048\n",
    "        # vowel_diacritic       \n",
    "        self.fc1 = nn.Conv2d(num_ch, 1, 1)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # extract features\n",
    "        #x = self.conv1(x)\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x).squeeze(2).squeeze(2)\n",
    "\n",
    "        #x1 = self.arcface(x).squeeze(2).squeeze(2)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = mymodel()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_fc = ArcMarginProduct(512, 2, s=100, m=0.5, easy_margin=False).to(device)\n",
    "optimizer = torch.optim.Adam([{'params': model.parameters()}, {'params': metric_fc.parameters()}],\n",
    "                                     lr=1e-3, weight_decay=1e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "exp_lr_scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, verbose=True, min_lr=1e-3*1e-3, factor=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    print('epochs {}/{} '.format(epoch+1,epochs))\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    acc1 = 0.0\n",
    "    acc2 = 0.0\n",
    "    acc3 = 0.0\n",
    "    t = tqdm(train_loader)\n",
    "    \n",
    "    for idx, (inputs,inputstrans,_,_,_) in enumerate(t):       \n",
    "        # send to gpu\n",
    "        inputs = inputs.to(device)\n",
    "        labels1 = torch.zeros(inputs.size()[0]).to(device).long() #.unsqueeze(1)\n",
    "        \n",
    "        # set opt\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # run model\n",
    "        feat = model(inputs.float())\n",
    "        outputs = metric_fc(feat, labels1)\n",
    "        #print(feat.size())\n",
    "        #print(labels1.size())\n",
    "        #print(outputs.size())\n",
    "        loss = criterion(outputs,labels1)\n",
    "        running_loss += loss\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        t.set_description(f't (l={running_loss/(idx+1):.3f})')\n",
    "    # save logs\n",
    "    log_epoch = {'epoch': epoch+1, 'lr': optimizer.state_dict()['param_groups'][0]['lr'],\n",
    "                     'loss': running_loss/len(train_loader)}\n",
    "    logs_train.append(log_epoch)\n",
    "    df = pd.DataFrame(logs_train)\n",
    "    df.to_csv(\"log/log_output_train_arc.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(epoch):\n",
    "    model.eval()\n",
    "    print('epochs {}/{} '.format(epoch+1,epochs))\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    acc1 = 0.0\n",
    "    acc2 = 0.0\n",
    "    acc3 = 0.0\n",
    "    t = tqdm(dev_loader)\n",
    "    \n",
    "    for idx, (inputs,inputstrans,_,_,_) in enumerate(t):       \n",
    "        # send to gpu\n",
    "        inputs = inputs.to(device)\n",
    "        labels1 = torch.zeros(inputs.size()[0]).to(device).long() #.unsqueeze(1)\n",
    "        \n",
    "        # set opt\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # run model\n",
    "        with torch.no_grad():\n",
    "            feat = model(inputs.float())\n",
    "            outputs = metric_fc(feat, labels1)\n",
    "        #print(outputs)\n",
    "        #print(feat.size())\n",
    "        #print(labels1.size())\n",
    "        #print(outputs.size())\n",
    "        loss = criterion(outputs,labels1)\n",
    "        running_loss += loss\n",
    "        \n",
    "        #loss.backward()\n",
    "        #optimizer.step()\n",
    "        \n",
    "        t.set_description(f't (l={running_loss/(idx+1):.3f})')\n",
    "    # save logs\n",
    "    log_epoch = {'epoch': epoch+1, 'lr': optimizer.state_dict()['param_groups'][0]['lr'],\n",
    "                     'loss': running_loss/len(dev_loader)}\n",
    "    logs_eval.append(log_epoch)\n",
    "    df = pd.DataFrame(logs_eval)\n",
    "    df.to_csv(\"log/log_output_eval_arc.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "import gc\n",
    "logs_eval = [];logs_train = [];\n",
    "model.load_state_dict(torch.load('./models/arcface_saved_weights.pth'))\n",
    "if TRAIN:\n",
    "    for epoch in range(epochs):\n",
    "        # GC\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        #train(epoch)\n",
    "        eval(epoch)\n",
    "        train(epoch)\n",
    "        torch.save(model.state_dict(), './models/{}arcface_saved_weights.pth'.format(epoch))\n",
    "        \n",
    "else:\n",
    "    model.load_state_dict(torch.load('./models/{}arcface_saved_weights.pth'.format(load_epoch)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(dataloader):\n",
    "    t = tqdm(dataloader)  \n",
    "    for idx, (inputs,_,_,_,_) in enumerate(t):       \n",
    "        # send to gpu\n",
    "        inputs = inputs.to(device)\n",
    "        # run model\n",
    "        with torch.no_grad():\n",
    "            out = model(inputs.float())\n",
    "        if idx  == 0:\n",
    "            outs = out\n",
    "        else:\n",
    "            outs = torch.cat((outs, out))\n",
    "\n",
    "    return outs.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel_launcher.py:2: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7f5f7ff7adc43b79bbe1b6e9704d710",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=604.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b666e75b41d4e7ab97ea27ec0c6460f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=151.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9918dcd2b1f47168f59da7965201c69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=30.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# get feature matrix\n",
    "train_results = inference(train_loader)\n",
    "test_seen = inference(dev_loader)\n",
    "test_unseen = inference(unseen_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(154610, 512)\n",
      "(38652, 512)\n",
      "(7578, 512)\n"
     ]
    }
   ],
   "source": [
    "print(train_results.shape)\n",
    "print(test_seen.shape)\n",
    "print(test_unseen.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get distance.\n",
    "def cosin_metric(x1, x2):\n",
    "    return np.dot(x1, x2)# / (np.linalg.norm(x1) * np.linalg.norm(x2))\n",
    "\n",
    "nmax = 100\n",
    "\n",
    "test_seen = np.clip(np.mean(cosin_metric(train_results, test_seen.T), axis=0), 0, nmax)\n",
    "test_unseen = np.clip(np.mean(cosin_metric(train_results, test_unseen.T), axis=0), 0, nmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print scatter plot of same 1s\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(test_seen)\n",
    "plt.show()\n",
    "plt.plot(test_unseen)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot roc curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_y = np.concatenate([test_seen, test_unseen])\n",
    "samelabel = np.zeros_like(test_seen)\n",
    "diflabel = np.ones_like(test_unseen)\n",
    "test_y = np.concatenate([samelabel, diflabel])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# FPR, TPR(, しきい値) を算出\n",
    "fpr, tpr, thresholds = metrics.roc_curve(test_y, predict_y)\n",
    "# ついでにAUCも\n",
    "auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "# ROC曲線をプロット\n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %.2f)'%auc)\n",
    "plt.legend()\n",
    "plt.title('ROC curve')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
